{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb24ebbf",
   "metadata": {},
   "source": [
    "# Monster Hunter Franchise Review Sentiment Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa83e45",
   "metadata": {},
   "source": [
    "## 1. Read Scrapping Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24702d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17353c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "      <th>is_recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://steamcommunity.com/id/xSinek/recommend...</td>\n",
       "      <td>Monster Hunter Wilds: A Majestic Hunt Marred b...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://steamcommunity.com/id/ze11an/recommend...</td>\n",
       "      <td>Ride monster,Life good,Monster fight back,Kill...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119829...</td>\n",
       "      <td>If this review gets 1 like I will get an Arkve...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://steamcommunity.com/id/xSinek/recommend...   \n",
       "1  https://steamcommunity.com/id/ze11an/recommend...   \n",
       "2  https://steamcommunity.com/profiles/7656119829...   \n",
       "\n",
       "                                              review is_recommended  \n",
       "0  Monster Hunter Wilds: A Majestic Hunt Marred b...    Recommended  \n",
       "1  Ride monster,Life good,Monster fight back,Kill...    Recommended  \n",
       "2  If this review gets 1 like I will get an Arkve...    Recommended  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['url', 'review', 'is_recommended']\n",
    "\n",
    "df_mhwilds = pd.read_csv(\"./data/mhwilds-reviews.csv\", header=None, names=column_names)\n",
    "df_mhwilds.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a89a9f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "      <th>is_recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119816...</td>\n",
       "      <td>I've been playing for 3 Hours and its already ...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://steamcommunity.com/id/metaLfaceshriLL/...</td>\n",
       "      <td>I LOVE KILLING ENDANGERED SPECIES</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119831...</td>\n",
       "      <td>Many monsters think they can outsmart me with ...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://steamcommunity.com/profiles/7656119816...   \n",
       "1  https://steamcommunity.com/id/metaLfaceshriLL/...   \n",
       "2  https://steamcommunity.com/profiles/7656119831...   \n",
       "\n",
       "                                              review is_recommended  \n",
       "0  I've been playing for 3 Hours and its already ...    Recommended  \n",
       "1                  I LOVE KILLING ENDANGERED SPECIES    Recommended  \n",
       "2  Many monsters think they can outsmart me with ...    Recommended  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mhrise = pd.read_csv(\"./data/mhrise-reviews.csv\", header=None, names=column_names)\n",
    "df_mhrise.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88fc54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "      <th>is_recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://steamcommunity.com/id/xSinek/recommend...</td>\n",
       "      <td>Monster Hunter Wilds: A Majestic Hunt Marred b...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://steamcommunity.com/id/ze11an/recommend...</td>\n",
       "      <td>Ride monster,Life good,Monster fight back,Kill...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119829...</td>\n",
       "      <td>If this review gets 1 like I will get an Arkve...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119948...</td>\n",
       "      <td>My grandma runs better than this game</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://steamcommunity.com/id/kirigherkins/rec...</td>\n",
       "      <td>very immersive game. you can cook a well-done ...</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18595</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119798...</td>\n",
       "      <td>DRM that breaks the game.</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18596</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119805...</td>\n",
       "      <td>Capcom decided to break another game that work...</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18597</th>\n",
       "      <td>https://steamcommunity.com/id/sopheon/recommen...</td>\n",
       "      <td>New DRM added years after release left the gam...</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18598</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119820...</td>\n",
       "      <td>Adding DRM to a game that came out two years a...</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18599</th>\n",
       "      <td>https://steamcommunity.com/id/blaster__master/...</td>\n",
       "      <td>Take your DRM and shove it capcom, your alread...</td>\n",
       "      <td>Not Recommended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18600 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://steamcommunity.com/id/xSinek/recommend...   \n",
       "1      https://steamcommunity.com/id/ze11an/recommend...   \n",
       "2      https://steamcommunity.com/profiles/7656119829...   \n",
       "3      https://steamcommunity.com/profiles/7656119948...   \n",
       "4      https://steamcommunity.com/id/kirigherkins/rec...   \n",
       "...                                                  ...   \n",
       "18595  https://steamcommunity.com/profiles/7656119798...   \n",
       "18596  https://steamcommunity.com/profiles/7656119805...   \n",
       "18597  https://steamcommunity.com/id/sopheon/recommen...   \n",
       "18598  https://steamcommunity.com/profiles/7656119820...   \n",
       "18599  https://steamcommunity.com/id/blaster__master/...   \n",
       "\n",
       "                                                  review   is_recommended  \n",
       "0      Monster Hunter Wilds: A Majestic Hunt Marred b...      Recommended  \n",
       "1      Ride monster,Life good,Monster fight back,Kill...      Recommended  \n",
       "2      If this review gets 1 like I will get an Arkve...      Recommended  \n",
       "3                  My grandma runs better than this game  Not Recommended  \n",
       "4      very immersive game. you can cook a well-done ...      Recommended  \n",
       "...                                                  ...              ...  \n",
       "18595                          DRM that breaks the game.  Not Recommended  \n",
       "18596  Capcom decided to break another game that work...  Not Recommended  \n",
       "18597  New DRM added years after release left the gam...  Not Recommended  \n",
       "18598  Adding DRM to a game that came out two years a...  Not Recommended  \n",
       "18599  Take your DRM and shove it capcom, your alread...  Not Recommended  \n",
       "\n",
       "[18600 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monsterhunter = pd.concat([df_mhwilds, df_mhrise], ignore_index=True)\n",
    "df_monsterhunter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74fe4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "      <th>is_recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18600</td>\n",
       "      <td>18581</td>\n",
       "      <td>18600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18598</td>\n",
       "      <td>17860</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119807...</td>\n",
       "      <td>yes</td>\n",
       "      <td>Recommended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>9888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url review  \\\n",
       "count                                               18600  18581   \n",
       "unique                                              18598  17860   \n",
       "top     https://steamcommunity.com/profiles/7656119807...    yes   \n",
       "freq                                                    2     46   \n",
       "\n",
       "       is_recommended  \n",
       "count           18600  \n",
       "unique              2  \n",
       "top       Recommended  \n",
       "freq             9888  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_monsterhunter.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e4e6ed",
   "metadata": {},
   "source": [
    "## 2. Text Cleaning / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e200b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82d68372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c25431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_monsterhunter.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6721f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18600 entries, 0 to 18599\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   url             18600 non-null  object\n",
      " 1   review          18581 non-null  object\n",
      " 2   is_recommended  18600 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 436.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_prep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ffeef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18600 entries, 0 to 18599\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   url             18600 non-null  string\n",
      " 1   review          18581 non-null  string\n",
      " 2   is_recommended  18600 non-null  string\n",
      "dtypes: string(3)\n",
      "memory usage: 436.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_prep.url = df_prep.url.astype(\"string\")\n",
    "df_prep.review = df_prep.review.astype(\"string\")\n",
    "df_prep.is_recommended = df_prep.is_recommended.astype(\"string\")\n",
    "\n",
    "df_prep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609e19e",
   "metadata": {},
   "source": [
    "* Strip HTML tags, URLs, and special characters (e.g., \\n, emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa574221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z_\\s]', '', text)  # Keep only letters and spaces\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda9e87",
   "metadata": {},
   "source": [
    "* Lowercase conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ed7f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep['cleaned_review'] = df_prep['review'].apply(lambda x: clean_text(str(x)).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e549a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monster Hunter Wilds: A Majestic Hunt Marred b...</td>\n",
       "      <td>monster hunter wilds a majestic hunt marred by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ride monster,Life good,Monster fight back,Kill...</td>\n",
       "      <td>ride monsterlife goodmonster fight backkill mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If this review gets 1 like I will get an Arkve...</td>\n",
       "      <td>if this review gets  like i will get an arkvel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  Monster Hunter Wilds: A Majestic Hunt Marred b...   \n",
       "1  Ride monster,Life good,Monster fight back,Kill...   \n",
       "2  If this review gets 1 like I will get an Arkve...   \n",
       "\n",
       "                                      cleaned_review  \n",
       "0  monster hunter wilds a majestic hunt marred by...  \n",
       "1  ride monsterlife goodmonster fight backkill mo...  \n",
       "2  if this review gets  like i will get an arkvel...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep[[\"review\", \"cleaned_review\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938207fc",
   "metadata": {},
   "source": [
    "* Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50f6017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monster hunter wilds a majestic hunt marred by...</td>\n",
       "      <td>[monster, hunter, wilds, a, majestic, hunt, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ride monsterlife goodmonster fight backkill mo...</td>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if this review gets  like i will get an arkvel...</td>\n",
       "      <td>[if, this, review, gets, like, i, will, get, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review  \\\n",
       "0  monster hunter wilds a majestic hunt marred by...   \n",
       "1  ride monsterlife goodmonster fight backkill mo...   \n",
       "2  if this review gets  like i will get an arkvel...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [monster, hunter, wilds, a, majestic, hunt, ma...  \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...  \n",
       "2  [if, this, review, gets, like, i, will, get, a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['tokens'] = df_prep['cleaned_review'].apply(word_tokenize)\n",
    "df_prep[[\"cleaned_review\", \"tokens\"]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32b1605",
   "metadata": {},
   "source": [
    "* Lemmatization/Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf783b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa66e0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[monster, hunter, wilds, a, majestic, hunt, ma...</td>\n",
       "      <td>[monster, hunter, wild, majestic, hunt, marred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[if, this, review, gets, like, i, will, get, a...</td>\n",
       "      <td>[review, get, like, get, arkveld, tattoo, fore...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [monster, hunter, wilds, a, majestic, hunt, ma...   \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...   \n",
       "2  [if, this, review, gets, like, i, will, get, a...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [monster, hunter, wild, majestic, hunt, marred...  \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...  \n",
       "2  [review, get, like, get, arkveld, tattoo, fore...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['lemmatized'] = df_prep['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x if word not in stop_words])\n",
    "df_prep[[\"tokens\", \"lemmatized\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39fab8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monster hunter wild majestic hunt marred techn...</td>\n",
       "      <td>[monster, hunter, wild, majestic, hunt, marred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ride monsterlife goodmonster fight backkill mo...</td>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review get like get arkveld tattoo forehead</td>\n",
       "      <td>[review, get, like, get, arkveld, tattoo, fore...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_review  \\\n",
       "0  monster hunter wild majestic hunt marred techn...   \n",
       "1  ride monsterlife goodmonster fight backkill mo...   \n",
       "2        review get like get arkveld tattoo forehead   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [monster, hunter, wild, majestic, hunt, marred...  \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...  \n",
       "2  [review, get, like, get, arkveld, tattoo, fore...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep['cleaned_review'] = df_prep['lemmatized'].apply(lambda x: ' '.join(x))\n",
    "df_prep[[\"cleaned_review\", \"lemmatized\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7cacc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep = df_prep[df_prep['cleaned_review'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07998a6d",
   "metadata": {},
   "source": [
    "* Labeling Review Score Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064c5105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18397/18397 [00:04<00:00, 3925.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>review</th>\n",
       "      <th>is_recommended</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://steamcommunity.com/id/xSinek/recommend...</td>\n",
       "      <td>Monster Hunter Wilds: A Majestic Hunt Marred b...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>monster hunter wild majestic hunt marred techn...</td>\n",
       "      <td>[monster, hunter, wilds, a, majestic, hunt, ma...</td>\n",
       "      <td>[monster, hunter, wild, majestic, hunt, marred...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://steamcommunity.com/id/ze11an/recommend...</td>\n",
       "      <td>Ride monster,Life good,Monster fight back,Kill...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>ride monsterlife goodmonster fight backkill mo...</td>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "      <td>[ride, monsterlife, goodmonster, fight, backki...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://steamcommunity.com/profiles/7656119829...</td>\n",
       "      <td>If this review gets 1 like I will get an Arkve...</td>\n",
       "      <td>Recommended</td>\n",
       "      <td>review get like get arkveld tattoo forehead</td>\n",
       "      <td>[if, this, review, gets, like, i, will, get, a...</td>\n",
       "      <td>[review, get, like, get, arkveld, tattoo, fore...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://steamcommunity.com/id/xSinek/recommend...   \n",
       "1  https://steamcommunity.com/id/ze11an/recommend...   \n",
       "2  https://steamcommunity.com/profiles/7656119829...   \n",
       "\n",
       "                                              review is_recommended  \\\n",
       "0  Monster Hunter Wilds: A Majestic Hunt Marred b...    Recommended   \n",
       "1  Ride monster,Life good,Monster fight back,Kill...    Recommended   \n",
       "2  If this review gets 1 like I will get an Arkve...    Recommended   \n",
       "\n",
       "                                      cleaned_review  \\\n",
       "0  monster hunter wild majestic hunt marred techn...   \n",
       "1  ride monsterlife goodmonster fight backkill mo...   \n",
       "2        review get like get arkveld tattoo forehead   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [monster, hunter, wilds, a, majestic, hunt, ma...   \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...   \n",
       "2  [if, this, review, gets, like, i, will, get, a...   \n",
       "\n",
       "                                          lemmatized sentiment  \n",
       "0  [monster, hunter, wild, majestic, hunt, marred...  positive  \n",
       "1  [ride, monsterlife, goodmonster, fight, backki...  negative  \n",
       "2  [review, get, like, get, arkveld, tattoo, fore...  positive  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    scores = sid.polarity_scores(text)\n",
    "    if scores['compound'] > 0.05:\n",
    "        return 'positive'\n",
    "    elif scores['compound'] < -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df_prep['sentiment'] = df_prep['cleaned_review'].progress_apply(get_sentiment)\n",
    "df_prep.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19f62279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    10847\n",
       "negative     4040\n",
       "neutral      3510\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0304f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_prep[\"cleaned_review\"], df_prep[\"sentiment\"], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "811df7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (14717,)\n",
      "Test data: (3680,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {x_train.shape}\")\n",
    "print(f\"Test data: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad2bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4322bdd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97c52ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label: ['neutral', 'positive', 'neutral']\n",
      "Train encoded label: [1 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train label: {list(y_train[:3])}\")\n",
    "print(f\"Train encoded label: {y_train_encoded[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "698b1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label: ['positive', 'positive', 'negative']\n",
      "Train encoded label: [2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train label: {list(y_test[:3])}\")\n",
    "print(f\"Train encoded label: {y_test_encoded[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c124fbd8",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc3ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7de1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_texts_2d(texts, tokenizer, model, max_length=128, batch_size=32):\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_ids, batch_mask in tqdm(loader, desc=\"Encoding Batches\"):\n",
    "            batch_ids = batch_ids.to(device)\n",
    "            batch_mask = batch_mask.to(device)\n",
    "            outputs = model(input_ids=batch_ids, attention_mask=batch_mask)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "            all_embeddings.append(cls_embeddings.cpu())\n",
    "\n",
    "    return torch.cat(all_embeddings, dim=0)  # Shape: (num_texts, hidden_size)\n",
    "\n",
    "\n",
    "def encode_texts_3d(texts, tokenizer, model, max_length=128, batch_size=32):\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'])\n",
    "    loader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    all_token_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_ids, batch_mask in tqdm(loader, desc=\"Encoding Batches\"):\n",
    "            batch_ids = batch_ids.to(device)\n",
    "            batch_mask = batch_mask.to(device)\n",
    "            outputs = model(input_ids=batch_ids, attention_mask=batch_mask)\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            all_token_embeddings.append(token_embeddings.cpu())\n",
    "\n",
    "    return torch.cat(all_token_embeddings, dim=0)  # Shape: (num_texts, seq_len, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf04a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA H100 80GB HBM3\n",
      "Sun May 25 05:48:03 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:66:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             73W /  700W |       4MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    !nvidia-smi\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab3d65",
   "metadata": {},
   "source": [
    "### 1. TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed67876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "x_train_tfidf = tfidf.fit_transform(x_train)\n",
    "x_test_tfidf = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0e7b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (14717, 5000)\n",
      "Test data: (3680, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {x_train_tfidf.shape}\")\n",
    "print(f\"Test data: {x_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c4c28",
   "metadata": {},
   "source": [
    "### 2. BERT (Bidirectional Encoder Representations from Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4ab7e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking')\n",
    "bert = BertModel.from_pretrained('bert-large-uncased-whole-word-masking').to(device)\n",
    "\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "bert.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3fdab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:09<00:00, 46.91it/s]\n",
      "Encoding Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [00:01<00:00, 64.04it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_bert = encode_texts_3d(list(x_train), bert_tokenizer, bert)\n",
    "x_test_bert = encode_texts_3d(list(x_test), bert_tokenizer, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55f4c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: torch.Size([14717, 128, 1024])\n",
      "Test data: torch.Size([3680, 128, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {x_train_bert.shape}\")\n",
    "print(f\"Test data: {x_test_bert.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbaa79e",
   "metadata": {},
   "source": [
    "### 3. XLM-RoBERTa (Cross-lingual Language Model RoBERTa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "008dac5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaModel(\n",
       "  (embeddings): XLMRobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): XLMRobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x XLMRobertaLayer(\n",
       "        (attention): XLMRobertaAttention(\n",
       "          (self): XLMRobertaSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): XLMRobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): XLMRobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): XLMRobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): XLMRobertaPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaModel\n",
    "\n",
    "xlmroberta_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-large')\n",
    "xlmroberta = XLMRobertaModel.from_pretrained('xlm-roberta-large').to(device)\n",
    "\n",
    "for param in xlmroberta.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "xlmroberta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed96707c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 460/460 [00:07<00:00, 60.59it/s]\n",
      "Encoding Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115/115 [00:01<00:00, 68.32it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_xlmroberta = encode_texts_3d(list(x_train), xlmroberta_tokenizer, xlmroberta)\n",
    "x_test_xlmroberta = encode_texts_3d(list(x_test), xlmroberta_tokenizer, xlmroberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7761c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: torch.Size([14717, 128, 1024])\n",
      "Test data: torch.Size([3680, 128, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {x_train_xlmroberta.shape}\")\n",
    "print(f\"Test data: {x_test_xlmroberta.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e448e8fd",
   "metadata": {},
   "source": [
    "## 4. Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6381a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bafe6e",
   "metadata": {},
   "source": [
    "**1. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3902681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2d999",
   "metadata": {},
   "source": [
    "**2. LSTM Classifier Head**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1d20e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifierHead(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_layers=1, hidden_dim = 128, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        lstm_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        \n",
    "        if self.lstm.bidirectional:\n",
    "            h_n = torch.cat((h_n[-2], h_n[-1]), dim=1)\n",
    "        else:\n",
    "            h_n = h_n[-1] \n",
    "        \n",
    "        return self.classifier(h_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36468057",
   "metadata": {},
   "source": [
    "### TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cf60199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LR Train Accuracy: 0.9148603655636339\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train_tfidf, y_train)\n",
    "print(\"TF-IDF + LR Train Accuracy:\", lr.score(x_train_tfidf, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4b7d292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF + LR Test Accuracy: 0.8548913043478261\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF + LR Test Accuracy:\", lr.score(x_test_tfidf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "517bf0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/tfidf_logreg.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr, \"models/tfidf_logreg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7aea54",
   "metadata": {},
   "source": [
    "### BERT + LSTM Classifier Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "880607f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierHead(\n",
       "  (lstm): LSTM(1024, 128, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_bert = LSTMClassifierHead(input_dim=x_train_bert.shape[-1], num_classes=3, bidirectional=False).to(device)\n",
    "lstm_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8f127f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|â–ˆ         | 10/100 [00:58<08:40,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100 | Train Loss: 0.7696 | Train Acc: 0.8027 | Test Loss: 0.0001 | Test Acc: 0.9355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|â–ˆâ–ˆ        | 20/100 [01:56<07:43,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100 | Train Loss: 1.5124 | Train Acc: 0.7997 | Test Loss: 0.0001 | Test Acc: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [02:53<06:49,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100 | Train Loss: 1.6038 | Train Acc: 0.7984 | Test Loss: 0.0001 | Test Acc: 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [03:52<05:52,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100 | Train Loss: 1.8310 | Train Acc: 0.8011 | Test Loss: 0.0001 | Test Acc: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [04:49<04:45,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100 | Train Loss: 1.7942 | Train Acc: 0.7976 | Test Loss: 0.0001 | Test Acc: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [05:47<03:52,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100 | Train Loss: 1.6300 | Train Acc: 0.7965 | Test Loss: 0.0001 | Test Acc: 0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [06:45<02:54,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/100 | Train Loss: 1.8069 | Train Acc: 0.8000 | Test Loss: 0.0001 | Test Acc: 0.9941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [07:44<01:58,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/100 | Train Loss: 1.9584 | Train Acc: 0.7981 | Test Loss: 0.0001 | Test Acc: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [08:43<00:58,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/100 | Train Loss: 1.9894 | Train Acc: 0.8052 | Test Loss: 0.0001 | Test Acc: 0.9942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:41<00:00,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/100 | Train Loss: 1.7667 | Train Acc: 0.7924 | Test Loss: 0.0001 | Test Acc: 0.9957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(x_train_bert, torch.tensor(y_train_encoded))\n",
    "test_ds  = TensorDataset(x_test_bert,  torch.tensor(y_test_encoded))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, num_workers=4, pin_memory=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_bert.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in trange(num_epochs, desc=\"Training Epochs\"):\n",
    "    lstm_bert.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        preds = lstm_bert(Xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(lstm_bert.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * yb.size(0)\n",
    "        train_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "        train_total += yb.size(0)\n",
    "\n",
    "    # Evaluation on test set\n",
    "    lstm_bert.eval()\n",
    "    test_loss_total, test_correct, test_total =  0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = lstm_bert(Xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            test_loss_total += loss.item() * yb.size(0)\n",
    "            test_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "            test_total += yb.size(0)\n",
    "            \n",
    "    train_acc = test_correct / test_total\n",
    "    train_loss = test_loss_total / test_total\n",
    "    test_acc = train_correct / train_total\n",
    "    test_loss = train_loss / train_total\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f23cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_bert, \"./models/lstm_bert.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd5808",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa + LSTM Classifier Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79a2b997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMClassifierHead(\n",
       "  (lstm): LSTM(1024, 128, batch_first=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_xlmroberta = LSTMClassifierHead(input_dim=x_train_xlmroberta.shape[-1], num_classes=3, bidirectional=False).to(device)\n",
    "lstm_xlmroberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51de82fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|â–ˆ         | 10/100 [00:57<08:37,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100 | Train Loss: 0.5815 | Train Acc: 0.7633 | Test Loss: 0.0000 | Test Acc: 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|â–ˆâ–ˆ        | 20/100 [01:54<07:39,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100 | Train Loss: 0.7417 | Train Acc: 0.7595 | Test Loss: 0.0001 | Test Acc: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [02:54<07:05,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100 | Train Loss: 0.8040 | Train Acc: 0.7560 | Test Loss: 0.0001 | Test Acc: 0.8591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [03:53<05:50,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100 | Train Loss: 0.9659 | Train Acc: 0.7315 | Test Loss: 0.0001 | Test Acc: 0.8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [04:53<04:58,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100 | Train Loss: 1.0459 | Train Acc: 0.7457 | Test Loss: 0.0001 | Test Acc: 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [05:52<03:58,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100 | Train Loss: 1.2853 | Train Acc: 0.7413 | Test Loss: 0.0001 | Test Acc: 0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [06:51<02:57,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/100 | Train Loss: 1.3424 | Train Acc: 0.7543 | Test Loss: 0.0001 | Test Acc: 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [07:50<01:57,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/100 | Train Loss: 1.6967 | Train Acc: 0.7410 | Test Loss: 0.0001 | Test Acc: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [08:49<00:59,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/100 | Train Loss: 1.7035 | Train Acc: 0.7326 | Test Loss: 0.0001 | Test Acc: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [09:49<00:00,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/100 | Train Loss: 1.7476 | Train Acc: 0.7459 | Test Loss: 0.0001 | Test Acc: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = TensorDataset(x_train_xlmroberta, torch.tensor(y_train_encoded))\n",
    "test_ds  = TensorDataset(x_test_xlmroberta,  torch.tensor(y_test_encoded))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, num_workers=4, pin_memory=True)\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_xlmroberta.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in trange(num_epochs, desc=\"Training Epochs\"):\n",
    "    lstm_xlmroberta.train()\n",
    "    train_loss, train_correct, train_total = 0.0, 0, 0\n",
    "\n",
    "    for Xb, yb in train_loader:\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "\n",
    "        preds = lstm_xlmroberta(Xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(lstm_xlmroberta.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * yb.size(0)\n",
    "        train_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "        train_total += yb.size(0)\n",
    "\n",
    "    # Evaluation on test set\n",
    "    lstm_xlmroberta.eval()\n",
    "    test_loss_total, test_correct, test_total =  0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = lstm_xlmroberta(Xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            test_loss_total += loss.item() * yb.size(0)\n",
    "            test_correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "            test_total += yb.size(0)\n",
    "            \n",
    "    train_acc = test_correct / test_total\n",
    "    train_loss = test_loss_total / test_total\n",
    "    test_acc = train_correct / train_total\n",
    "    test_loss = train_loss / train_total\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ec934ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_xlmroberta, \"./models/lstm_xlmroberta.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66489ddb",
   "metadata": {},
   "source": [
    "## 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "68c4c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "class SentimentAnalysis():\n",
    "    def __init__(self, model_path: str, bert_path: str = \"bert-large-uncased-whole-word-masking\"):\n",
    "        nltk.download(\"stopwords\")\n",
    "        nltk.download(\"wordnet\")\n",
    "        nltk.download('punkt_tab')\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "        self.classifier = torch.load(model_path, map_location=self.device)\n",
    "        self.classifier.eval().to(self.device)\n",
    "\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "        self.bert = BertModel.from_pretrained(bert_path).to(self.device)\n",
    "        \n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def __preprocessing(self, text: str):\n",
    "        # Clean text\n",
    "        text = re.sub(r'<.*?>', '', text)  # Remove HTML tags\n",
    "        text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "        text = text.lower().strip()\n",
    "\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Remove stopwords and lemmatize\n",
    "        lemmatized = [\n",
    "            self.lemmatizer.lemmatize(word)\n",
    "            for word in tokens\n",
    "            if word not in self.stop_words\n",
    "        ]\n",
    "\n",
    "        return \" \".join(lemmatized)\n",
    "        \n",
    "        \n",
    "    def predict(self, text: str):\n",
    "        text = self.__preprocessing(text)\n",
    "\n",
    "        encoded = self.bert_tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=128\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert(**encoded)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "            logits = self.classifier(cls_embedding.unsqueeze(0))\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            conf, pred_id = torch.max(probs, dim=1)\n",
    "\n",
    "            label = self.label_map[pred_id.item()]\n",
    "            confidence = conf.item()\n",
    "\n",
    "        return label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bf601b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 25 07:18:27 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  |   00000000:66:00.0 Off |                    0 |\n",
      "| N/A   39C    P0            121W /  700W |    8086MiB /  81559MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35c08817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis = SentimentAnalysis(\"./models/lstm_bert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36376ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "Input Text     : Good Game, I recommend you guys to try it!\n",
      "Predicted Label: Positive\n",
      "Confidence     : 97.55%\n",
      "==============================================================\n",
      "CPU times: user 8.3 ms, sys: 377 Âµs, total: 8.68 ms\n",
      "Wall time: 8.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = \"Good Game, I recommend you guys to try it!\"\n",
    "pred, conf = sentiment_analysis.predict(text)\n",
    "\n",
    "separator_len = max(50, len(text) + 20)\n",
    "separator = \"=\" * separator_len\n",
    "\n",
    "print(separator)\n",
    "print(f\"Input Text     : {text}\")\n",
    "print(f\"Predicted Label: {pred.capitalize()}\")\n",
    "print(f\"Confidence     : {conf:.2%}\")\n",
    "print(separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9b99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
